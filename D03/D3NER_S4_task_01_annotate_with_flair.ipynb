{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Annotating Text with FlairNLP\n",
        "\n",
        "Flair is a powerful Sequence-Tagging framework that is easy to use for prediction, but also to train and finetune your own models with. The contextual character embeddings, that you have learned about are a central feature of flair, but you can use most other embedding types without much hassle.\n",
        "\n",
        "Flair is a deep learning architecture and will run much faster when you use a machine with a CUDA-compatible video card. Creating predictions\n",
        "will usually be fast enough without a video card, but it is strongly recommended when training a model.\n",
        "\n",
        "In this notebook, you learn how to use a pre-trained model to annotate text.\n",
        "\n",
        "You can find more helpful tutorials at https://flairnlp.github.io/."
      ],
      "metadata": {
        "id": "UUzskJayThXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v5GTB-VUSvvD"
      },
      "outputs": [],
      "source": [
        "# if flair isn't installed, install it (this can take a moment)\n",
        "%pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary parts of the library\n",
        "from flair.data import Sentence\n",
        "from flair.nn import Classifier"
      ],
      "metadata": {
        "id": "lRS08ZKqTPw1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Models\n",
        "Flair can retrieve models from two sources with the `load()` method, either from a local directory or from [Huggingface](https://huggingface.co/). There is also a list of abbreviated model names that can be found in the [flair tutorial](https://flairnlp.github.io/docs/tutorial-basics/tagging-entities) such as `ner-fast`, which will load a small version of the default NER model for english.\n",
        "\n",
        "If you want to use a local model, simply write the path instead of a model name.\n"
      ],
      "metadata": {
        "id": "7jGtOfpqTzxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a classifier\n",
        "tagger = Classifier.load('ner-fast')"
      ],
      "metadata": {
        "id": "XvAclnLdTw8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sentence object that will be predicted\n",
        "sentence = Sentence('Here you can see the land of East Anglia over the Humber estuary to York in Northumbria, and there was great discord among the people themselves, and they had overthrown their king Osbryht, and had accepted an illegitimate king named Ælla.')"
      ],
      "metadata": {
        "id": "fMwLUT_0U5Qi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the annotations\n",
        "tagger.predict(sentence)"
      ],
      "metadata": {
        "id": "rUZY_nrhTWzY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the annotations\n",
        "for label in sentence.get_labels():\n",
        "    print(label)"
      ],
      "metadata": {
        "id": "gIUOGvBHTu_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the sentence objects holds now information for all predicted annotations, including the indices from where to where the annotation goes, the category and a confidence score."
      ],
      "metadata": {
        "id": "G_NTPMrZWwW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using pre-trained models on historical text\n",
        "\n",
        "Try the original passage instead now:\n",
        "\n",
        "> Her for se here of East Englum ofer Humbremuþan to Eoforwicceastre on Norþhymbre, ond þær wæs micel ungeþuærnes þære þeode betweox him selfum, ond hie hæfdun hiera cyning aworpenne Osbryht, ond ungecyndne cyning underfengon Ællan;\n",
        "\n",
        "How well are the entities recognized?\n",
        "\n",
        "Experiment further:\n",
        "How well does the recognition work when you lowercase the sentence?\n",
        "How do other models perform?\n",
        "\n",
        "Test how your annotation on your own data looks when using the available models."
      ],
      "metadata": {
        "id": "0zHbcUshXGvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing the annotations\n",
        "In the next part, I will show how the annotations are accessible inside the sentence object. How to transform them for further use will depend on what you want to do with them."
      ],
      "metadata": {
        "id": "rdo7ZEPjYW4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations are stored as Span objects\n",
        "annotations = sentence.get_spans(\"ner\")\n",
        "print(annotations[0])"
      ],
      "metadata": {
        "id": "nmo5ikogYyvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can access all relevant information through these objects\n",
        "annotation = annotations[0]\n",
        "\n",
        "print(\"Start Index:\", annotation.start_position)  # note this returns character index, not token index\n",
        "print(\"End Index:\", annotation.end_position)  # note this returns character index, not token index\n",
        "print(\"Text:\", annotation.text)\n",
        "print(\"Text as Token Objects:\", annotation.tokens)\n",
        "print(\"Confidence:\", annotation.get_labels(\"ner\")[0].score)"
      ],
      "metadata": {
        "id": "-gn1m9U5ZPuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we could now for example use this to create some pseudo-TEI formatted string\n",
        "tags = [{} for i in range(len(sentence))]\n",
        "for entity in sentence.get_spans():\n",
        "    # start\n",
        "    start = entity.tokens[0].idx - 1\n",
        "    tags[start][\"start\"] = \"<\" + entity.get_labels()[0].value + \">\"\n",
        "    # end\n",
        "    end = entity.tokens[-1].idx - 1\n",
        "    tags[end][\"end\"] = \"</\" + entity.get_labels()[0].value + \">\"\n",
        "\n",
        "out_list = []\n",
        "for token, tag in zip(sentence, tags):\n",
        "    if \"start\" in tag:\n",
        "        out_list.append(tag[\"start\"])\n",
        "    out_list.append(token.text)\n",
        "    if \"end\" in tag:\n",
        "        out_list.append(tag[\"end\"])\n",
        "\n",
        "out_xml = \"<tei>\" + \" \".join(out_list) + \"</tei>\"\n",
        "\n",
        "print(out_xml)"
      ],
      "metadata": {
        "id": "1R72f-DxaXEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}