
@article{grishman_twenty-five_2019,
	title = {Twenty-five years of information extraction},
	volume = {25},
	issn = {1351-3249, 1469-8110},
	url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/twentyfive-years-of-information-extraction/0E5BB0D6AE906BB3C25037E2D74CA8F3},
	doi = {10.1017/S1351324919000512},
	abstract = {Information extraction is the process of converting unstructured text into a structured data base containing selected information from the text. It is an essential step in making the information content of the text usable for further processing. In this paper, we describe how information extraction has changed over the past 25 years, moving from hand-coded rules to neural networks, with a few stops on the way. We connect these changes to research advances in {NLP} and to the evaluations organized by the {US} Government.},
	pages = {677--692},
	number = {6},
	journaltitle = {Natural Language Engineering},
	author = {Grishman, Ralph},
	urldate = {2019-11-10},
	date = {2019-11},
	langid = {english},
	keywords = {Information extraction, Message understanding},
	file = {Snapshot:C\:\\Users\\vogeler\\Zotero\\storage\\ZBNTL7MJ\\0E5BB0D6AE906BB3C25037E2D74CA8F3.html:text/html},
}

@article{toledo_information_2019,
	title = {Information extraction from historical handwritten document images with a context-aware neural model},
	volume = {86},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320318303145},
	doi = {10.1016/j.patcog.2018.08.020},
	abstract = {Many historical manuscripts that hold trustworthy memories of the past societies contain information organized in a structured layout (e.g. census, birth or marriage records). The precious information stored in these documents cannot be effectively used nor accessed without costly annotation efforts. The transcription driven by the semantic categories of words is crucial for the subsequent access. In this paper we describe an approach to extract information from structured historical handwritten text images and build a knowledge representation for the extraction of meaning out of historical data. The method extracts information, such as named entities, without the need of an intermediate transcription step, thanks to the incorporation of context information through language models. Our system has two variants, the first one is based on bigrams, whereas the second one is based on recurrent neural networks. Concretely, our second architecture integrates a Convolutional Neural Network to model visual information from word images together with a Bidirecitonal Long Short Term Memory network to model the relation among the words. This integrated sequential approach is able to extract more information than just the semantic category (e.g. a semantic category can be associated to a person in a record). Our system is generic, it deals with out-of-vocabulary words by design, and it can be applied to structured handwritten texts from different domains. The method has been validated with the {ICDAR} {IEHHR} competition protocol, outperforming the existing approaches.},
	pages = {27--36},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Toledo, J. Ignacio and Carbonell, Manuel and Fornés, Alicia and Lladós, Josep},
	urldate = {2019-11-10},
	date = {2019-02-01},
	langid = {english},
	keywords = {Document image analysis, Named entity recognition, Deep neural networks, Handwritten documents},
	file = {ScienceDirect Snapshot:C\:\\Users\\vogeler\\Zotero\\storage\\JMVDCYZZ\\S0031320318303145.html:text/html},
}

@inproceedings{schweter_towards_2019,
	title = {Towards Robust Named Entity Recognition for Historic German},
	url = {http://arxiv.org/abs/1906.07592},
	abstract = {Recent advances in language modeling using deep neural networks have shown that these models learn representations, that vary with the network depth from morphology to semantic relationships like co-reference. We apply pre-trained language models to low-resource named entity recognition for Historic German. We show on a series of experiments that character-based pre-trained language models do not run into trouble when faced with low-resource datasets. Our pre-trained character-based language models improve upon classical {CRF}-based methods and previous work on Bi-{LSTMs} by boosting F1 score performance by up to 6\%. Our pre-trained language and {NER} models are publicly available under https://github.com/stefan-it/historic-ner .},
	booktitle = {{arXiv}:1906.07592 [cs]},
	author = {Schweter, Stefan and Baiter, Johannes},
	urldate = {2020-04-01},
	date = {2019-06-18},
	eprinttype = {arxiv},
	eprint = {1906.07592},
	keywords = {Computer Science - Computation and Language, I.2.7},
	file = {arXiv Fulltext PDF:C\:\\Users\\vogeler\\Zotero\\storage\\L5NDPXGS\\Schweter und Baiter - 2019 - Towards Robust Named Entity Recognition for Histor.pdf:application/pdf;arXiv Fulltext PDF:C\:\\Users\\vogeler\\Zotero\\storage\\PSEP6EGG\\Schweter und Baiter - 2019 - Towards Robust Named Entity Recognition for Histor.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\vogeler\\Zotero\\storage\\MN3G63X3\\1906.html:text/html;arXiv.org Snapshot:C\:\\Users\\vogeler\\Zotero\\storage\\A4DJFMT9\\1906.html:text/html},
}

@inproceedings{todorov_transfer_2020,
	title = {Transfer Learning for Historical Corpora: An Assessment on Post-{OCR} Correction and Named Entity Recognition},
	series = {{CEUR} Workshop Proceedings},
	abstract = {Transfer learning in Natural Language Processing, mainly in the form of pre-trained language models, has recently delivered substantial gains across a range of tasks. Scholars and practitioners working with {OCRed} historical corpora are thus increasingly exploring the use of pre-trained language models. Nevertheless, the specific challenges posed by historical documents, including {OCR} quality and linguistic change, call for a critical assessment of the use of pre-trained language models in this setting. We consider two shared tasks, {ICDAR}2019 (post-{OCR} correction) and {CLEF}-{HIPE}-2020 (Named Entity Recognition, {NER}), and systematically assess using pre-trained language models with data in French, German and English. We find that using pre-trained language models helps with {NER} but less so with post-{OCR} correction. Pre-trained language models should therefore be used critically when working with {OCRed} historical corpora. We release our code base, in order to allow replicating our results and testing other pre-trained representations.},
	pages = {310--339},
	booktitle = {{CHR} 2020: Workshop on Computational Humanities Research, November 18–20, 2020, Amsterdam, The Netherlands},
	author = {Todorov, Konstantin and Colavizza, Giovanni},
	date = {2020},
	langid = {english},
	file = {Todorov und Colavizza - Transfer Learning for Historical Corpora An Asses.pdf:C\:\\Users\\vogeler\\Zotero\\storage\\Y6MGT7UL\\Todorov und Colavizza - Transfer Learning for Historical Corpora An Asses.pdf:application/pdf},
}

@inproceedings{boros_alleviating_2020,
	location = {Online},
	title = {Alleviating Digitization Errors in Named Entity Recognition for Historical Documents},
	url = {https://aclanthology.org/2020.conll-1.35},
	doi = {10.18653/v1/2020.conll-1.35},
	abstract = {This paper tackles the task of named entity recognition ({NER}) applied to digitized historical texts obtained from processing digital images of newspapers using optical character recognition ({OCR}) techniques. We argue that the main challenge for this task is that the {OCR} process leads to misspellings and linguistic errors in the output text. Moreover, historical variations can be present in aged documents, which can impact the performance of the {NER} process. We conduct a comparative evaluation on two historical datasets in German and French against previous state-of-the-art models, and we propose a model based on a hierarchical stack of Transformers to approach the {NER} task for historical data. Our findings show that the proposed model clearly improves the results on both historical datasets, and does not degrade the results for modern datasets.},
	eventtitle = {{CoNLL} 2020},
	pages = {431--441},
	booktitle = {Proceedings of the 24th Conference on Computational Natural Language Learning},
	publisher = {Association for Computational Linguistics},
	author = {Boroş, Emanuela and Hamdi, Ahmed and Linhares Pontes, Elvys and Cabrera-Diego, Luis Adrián and Moreno, Jose G. and Sidere, Nicolas and Doucet, Antoine},
	urldate = {2021-08-31},
	date = {2020-11},
	file = {Full Text PDF:C\:\\Users\\vogeler\\Zotero\\storage\\RP3RB55G\\Boros et al. - 2020 - Alleviating Digitization Errors in Named Entity Re.pdf:application/pdf},
}

@inproceedings{boros_interet_2021,
	location = {Lille, France},
	title = {Intérêt des modèles de caractères pour la détection d'événements (The interest of character-level models for event detection)},
	url = {https://aclanthology.org/2021.jeptalnrecital-taln.17},
	abstract = {Cet article aborde la tâche de détection d'événements, visant à identifier et catégoriser les mentions d'événements dans les textes. Une des difficultés de cette tâche est le problème des mentions d'événements correspondant à des mots mal orthographiés, très spécifiques ou hors vocabulaire. Pour analyser l'impact de leur prise en compte par le biais de modèles de caractères, nous proposons d'intégrer des plongements de caractères, qui peuvent capturer des informations morphologiques et de forme sur les mots, à un modèle convolutif pour la détection d'événements. Plus précisément, nous évaluons deux stratégies pour réaliser une telle intégration et montrons qu'une approche de fusion tardive surpasse à la fois une approche de fusion précoce et des modèles intégrant des informations sur les caractères ou les sous-mots tels que {ELMo} ou {BERT}.},
	eventtitle = {{JEP}/{TALN}/{RECITAL} 2021},
	pages = {179--188},
	booktitle = {Actes de la 28e Conférence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conférence principale},
	publisher = {{ATALA}},
	author = {Boroş, Emanuela and Besançon, Romaric and Ferret, Olivier and Grau, Brigitte},
	urldate = {2021-08-31},
	date = {2021-06},
	file = {Full Text PDF:C\:\\Users\\vogeler\\Zotero\\storage\\UNVELI3E\\Boros et al. - 2021 - Intérêt des modèles de caractères pour la détectio.pdf:application/pdf},
}

@inproceedings{boros_comparison_2020,
	title = {A comparison of sequential and combined approaches for named entity recognition in a corpus of handwritten medieval charters},
	doi = {10.1109/ICFHR2020.2020.00025},
	abstract = {This paper introduces a new corpus of multilingual medieval handwritten charter images, annotated with full transcription and named entities. The corpus is used to compare two approaches for named entity recognition in historical document images in several languages: on the one hand, a sequential approach, more commonly used, that sequentially applies handwritten text recognition ({HTR}) and named entity recognition ({NER}), on the other hand, a combined approach that simultaneously transcribes the image text line and extracts the entities. Experiments conducted on the charter corpus in Latin, early new high German and old Czech for name, date and location recognition demonstrate a superior performance of the combined approach.},
	eventtitle = {2020 17th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	pages = {79--84},
	booktitle = {2020 17th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	author = {Boroş, Emanuela and Romero, Verónica and Maarand, Martin and Zenklová, Kateřina and Křečková, Jitka and Vidal, Enrique and Stutzmann, Dominique and Kermorvant, Christopher},
	date = {2020-09},
	keywords = {Urkunde, Neural networks, Handwriting recognition, Optical character recognition software, Text recognition, Mathematical model, Adaptive optics, Handwritten Text Recognition, {NER}, Named entity recognition, {HTR}, Named Entity Recognition, Optical imaging, historical document processing, multilingualism},
	file = {Boros et al. - 2020 - A comparison of sequential and combined approaches.pdf:C\:\\Users\\vogeler\\Zotero\\storage\\KSGDHKDL\\Boros et al. - 2020 - A comparison of sequential and combined approaches.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\vogeler\\Zotero\\storage\\TJTR9EPV\\9257761.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\vogeler\\Zotero\\storage\\N7W4YTBY\\9257761.html:text/html},
}

@inproceedings{pontes_entity_2020,
	location = {Cham},
	title = {Entity Linking for Historical Documents: Challenges and Solutions},
	isbn = {978-3-030-64452-9},
	doi = {10.1007/978-3-030-64452-9_19},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Entity Linking for Historical Documents},
	abstract = {Named entities ({NEs}) are among the most relevant type of information that can be used to efficiently index and retrieve digital documents. Furthermore, the use of Entity Linking ({EL}) to disambiguate and relate {NEs} to knowledge bases, provides supplementary information which can be useful to differentiate ambiguous elements such as geographical locations and peoples’ names. In historical documents, the detection and disambiguation of {NEs} is a challenge. Most historical documents are converted into plain text using an optical character recognition ({OCR}) system at the expense of some noise. Documents in digital libraries will, therefore, be indexed with errors that may hinder their accessibility. {OCR} errors affect not only document indexing but the detection, disambiguation, and linking of {NEs}. This paper aims at analysing the performance of different {EL} approaches on two multilingual historical corpora, {CLEF} {HIPE} 2020 (English, French, German) and {NewsEye} (Finnish, French, German, Swedish), while proposes several techniques for alleviating the impact of historical data problems on the {EL} task. Our findings indicate that the proposed approaches not only outperform the baseline in both corpora but additionally they considerably reduce the impact of historical document issues on different subjects and languages.},
	pages = {215--231},
	booktitle = {Digital Libraries at Times of Massive Societal Transition},
	publisher = {Springer International Publishing},
	author = {Pontes, Elvys Linhares and Cabrera-Diego, Luis Adrián and Moreno, Jose G. and Boros, Emanuela and Hamdi, Ahmed and Sidère, Nicolas and Coustaty, Mickaël and Doucet, Antoine},
	editor = {Ishita, Emi and Pang, Natalie Lee San and Zhou, Lihong},
	date = {2020},
	langid = {english},
	keywords = {Deep learning, Digital libraries., Entity linking, Historical data},
	file = {Eingereichte Version:C\:\\Users\\vogeler\\Zotero\\storage\\NGVF4KUW\\Pontes et al. - 2020 - Entity Linking for Historical Documents Challenge.pdf:application/pdf},
}

@inproceedings{boros_robust_2020,
	location = {Thessaloniki, Greece},
	title = {Robust Named Entity Recognition and Linking on Historical Multilingual Documents},
	volume = {2696},
	url = {https://hal.archives-ouvertes.fr/hal-03026969},
	series = {Working Notes of {CLEF} 2020 - Conference and Labs of the Evaluation Forum},
	abstract = {This paper summarizes the participation of the L3i laboratory of the University of La Rochelle in the Identifying Historical People, Places, and other Entities ({HIPE}) evaluation campaign of {CLEF} 2020. Our participation relies on two neural models, one for named entity recognition and classification ({NERC}) and another one for entity linking ({EL}). We carefully pre-processed inputs to mitigate its flaws, notably in terms of segmentation. Our submitted runs cover all languages (English, French, and German) and sub-tasks proposed in the lab: {NERC}, endto-end {EL}, and {EL}-only. Our submissions obtained top performance in 50 out of the 52 scoreboards proposed by the lab organizers. In further detail, out of 70 runs submitted by 13 participants, our approaches obtained the best score for all metrics in all three languages both for {NERC} and for end-to-end {EL}. It also obtained the best score for all metrics in French and German for {EL}-only.},
	pages = {1--17},
	booktitle = {Conference and Labs of the Evaluation Forum ({CLEF} 2020)},
	publisher = {{CEUR}-{WS} Working Notes},
	author = {Boroş, Emanuela and Linhares Pontes, Elvys and Cabrera-Diego, Luis Adrián and Hamdi, Ahmed and Moreno, José G. and Sidère, Nicolas and Doucet, Antoine},
	urldate = {2021-08-31},
	date = {2020-09},
	note = {Issue: Paper 171},
	keywords = {Information extraction, Named Entity Recognition, Entity linking},
	file = {HAL PDF Full Text:C\:\\Users\\vogeler\\Zotero\\storage\\ZJPKZGCY\\Boros et al. - 2020 - Robust Named Entity Recognition and Linking on His.pdf:application/pdf},
}

@article{chastang_named_2021,
	title = {A Named Entity Recognition Model for Medieval Latin Charters},
	volume = {015},
	issn = {1938-4122},
	url = {http://www.digitalhumanities.org/dhq/vol/15/4/000574/000574.html},
	abstract = {Named entity recognition is an advantageous technique with an increasing presence in digital humanities. In theory, automatic detection and recovery of named entities can provide new ways of looking up unedited information in edited sources and can allow the parsing of a massive amount of data in a short time for supporting historical hypotheses. In this paper, we detail the implementation of a model for automatic named entity recognition in medieval Latin sources and we test its robustness on different datasets. Different models were trained on a vast dataset of Burgundian diplomatic charters from the 9th to 14th centuries and validated by using general and century ad hoc models tested on short sets of Parisian, English, Italian and Spanish charters. We present the results of cross-validation in each case and we discuss the implications of these results for the history of medieval place-names and personal names.},
	number = {4},
	journaltitle = {Digital Humanities Quarterly},
	shortjournal = {{DHQ}},
	author = {Chastang, Pierre and Aguilar, Sergio Torres and Tannier, Xavier},
	date = {2021},
	keywords = {Urkunde, Frankreich, Latein, {NER}},
	file = {DHQ\: Digital Humanities Quarterly\: A Named Entity Recognition Model for Medieval Latin Charters:C\:\\Users\\vogeler\\Zotero\\storage\\YMJME2VT\\000574.html:text/html},
}

@article{mcdonough_named_2019,
	title = {Named entity recognition goes to old regime France: geographic text analysis for early modern French corpora},
	volume = {33},
	issn = {1365-8816, 1362-3087},
	url = {https://www.tandfonline.com/doi/full/10.1080/13658816.2019.1620235},
	doi = {10.1080/13658816.2019.1620235},
	shorttitle = {Named entity recognition goes to old regime France},
	pages = {2498--2522},
	number = {12},
	journaltitle = {International Journal of Geographical Information Science},
	shortjournal = {International Journal of Geographical Information Science},
	author = {{McDonough}, Katherine and Moncla, Ludovic and van de Camp, Matje},
	urldate = {2021-12-04},
	date = {2019-12-02},
	langid = {english},
}

@inproceedings{torres_aguilar_named_2021,
	location = {Helsinki, Finland},
	title = {Named Entity Recognition for French medieval charters},
	url = {https://hal.archives-ouvertes.fr/hal-03503055},
	series = {Workshop on Natural Language Processing for Digital Humanities Proceedings of the Workshop},
	abstract = {This paper presents the process of annotating and modelling a corpus to automatically detect named entities in medieval charters in French. It introduces a new annotated corpus and a new system which outperforms state-of-the art libraries. Charters are legal documents and among the most important historical sources for medieval studies as they reflect economic and social dynamics as well as the evolution of literacy and writing practices. Automatic detection of named entities greatly improves the access to these unstructured texts and facilitates historical research. The experiments described here are based on a corpus encompassing about 500k words (1200 charters) coming from three charter collections of
the 13th and 14th centuries. We annotated the corpus and then trained two state-of-the art {NLP} libraries for Named Entity Recognition (Spacy and Flair) and a custom neural model (Bi-{LSTM}-{CRF}). The evaluation shows that all three models achieve a high performance rate on the test set and a high generalization capacity against two external corpora unseen during training. This paper describes the corpus and the annotation model, and discusses the issues related to the linguistic processing of medieval French and formulaic discourse, so as to interpret the results within a larger historical perspective.},
	booktitle = {Workshop on Natural Language Processing for Digital Humanities},
	author = {Torres Aguilar, Sergio and Stutzmann, Dominique},
	urldate = {2022-09-29},
	date = {2021-12},
	note = {00001},
	keywords = {natural language processing, cultural heritage, named entity recognition, ancien et moyen français, Old and Middle French, patrimoine culturel, reconnaissance des entités nommées, traitement automatique du langage naturel},
	file = {HAL PDF Full Text:C\:\\Users\\vogeler\\Zotero\\storage\\22K2Z4JV\\Torres Aguilar und Stutzmann - 2021 - Named Entity Recognition for French medieval chart.pdf:application/pdf},
}

@article{alam_semantic_2021,
	title = {Semantic role labeling for knowledge graph extraction from text},
	volume = {10},
	issn = {2192-6352, 2192-6360},
	url = {https://link.springer.com/10.1007/s13748-021-00241-7},
	doi = {10.1007/s13748-021-00241-7},
	abstract = {Abstract
            This paper introduces , a new semantic role labeling method that transforms a text into a frame-oriented knowledge graph. It performs dependency parsing, identifies the words that evoke lexical frames, locates the roles and fillers for each frame, runs coercion techniques, and formalizes the results as a knowledge graph. This formal representation complies with the frame semantics used in Framester, a factual-linguistic linked data resource. We tested our method on the {WSJ} section of the Peen Treebank annotated with {VerbNet} and {PropBank} labels and on the Brown corpus. The evaluation has been performed according to the {CoNLL} Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. The obtained precision, recall, and F1 values indicate that {TakeFive} is competitive with other existing methods such as {SEMAFOR}, Pikes, {PathLSTM}, and {FRED}. We finally discuss how to combine {TakeFive} and {FRED}, obtaining higher values of precision, recall, and F1 measure.},
	pages = {309--320},
	number = {3},
	journaltitle = {Progress in Artificial Intelligence},
	shortjournal = {Prog Artif Intell},
	author = {Alam, Mehwish and Gangemi, Aldo and Presutti, Valentina and Reforgiato Recupero, Diego},
	urldate = {2023-03-11},
	date = {2021-09},
	langid = {english},
	file = {Volltext:C\:\\Users\\vogeler\\Zotero\\storage\\S2KMGF35\\Alam et al. - 2021 - Semantic role labeling for knowledge graph extract.pdf:application/pdf},
}

@inproceedings{andres_information_2022,
	location = {Berlin, Heidelberg},
	title = {Information Extraction from Handwritten Tables in Historical Documents},
	isbn = {978-3-031-06554-5},
	url = {https://doi.org/10.1007/978-3-031-06555-2_13},
	doi = {10.1007/978-3-031-06555-2_13},
	abstract = {Recently, significant advances have been made in Document Understanding in structured historical documents. However, not much research has been done in information extraction from handwritten structured historical documents. In this paper, we compare two Machine Learning approaches and another approach that is based on heuristic rules to extract information in historical pre-printed forms with handwritten information. We analyze how each approach performs at each step of the extraction process. The proposed approaches improve the heuristic-rule baseline by up to 0.14 F-measure points throughout the information extraction pipeline.},
	pages = {184--198},
	booktitle = {Document Analysis Systems: 15th {IAPR} International Workshop, {DAS} 2022, La Rochelle, France, May 22–25, 2022, Proceedings},
	publisher = {Springer-Verlag},
	author = {Andrés, José and Prieto, Jose Ramón and Granell, Emilio and Romero, Verónica and Sánchez, Joan Andreu and Vidal, Enrique},
	urldate = {2023-04-21},
	date = {2022-05-22},
	keywords = {Neural networks, Information extraction, Structured handwritten documents},
}

@inproceedings{blouin_transferring_2021,
	location = {{NIT} Silchar, India},
	title = {Transferring Modern Named Entity Recognition to the Historical Domain: How to Take the Step?},
	url = {https://aclanthology.org/2021.nlp4dh-1.18},
	shorttitle = {Transferring Modern Named Entity Recognition to the Historical Domain},
	abstract = {Named entity recognition is of high interest to digital humanities, in particular when mining historical documents. Although the task is mature in the field of {NLP}, results of contemporary models are not satisfactory on challenging documents corresponding to out-of-domain genres, noisy {OCR} output, or old-variants of the target language. In this paper we study how model transfer methods, in the context of the aforementioned challenges, can improve historical named entity recognition according to how much effort is allocated to describing the target data, manually annotating small amounts of texts, or matching pre-training resources. In particular, we explore the situation where the class labels, as well as the quality of the documents to be processed, are different in the source and target domains. We perform extensive experiments with the transformer architecture on the {LitBank} and {HIPE} historical datasets, with different annotation schemes and character-level noise. They show that annotating 250 sentences can recover 93\% of the full-data performance when models are pre-trained, that the choice of self-supervised and target-task pre-training data is crucial in the zero-shot setting, and that {OCR} errors can be handled by simulating noise on pre-training data and resorting to recent character-aware transformers.},
	eventtitle = {{NLP}4DH 2021},
	pages = {152--162},
	booktitle = {Proceedings of the Workshop on Natural Language Processing for Digital Humanities},
	publisher = {{NLP} Association of India ({NLPAI})},
	author = {Blouin, Baptiste and Favre, Benoit and Auguste, Jeremy and Henriot, Christian},
	urldate = {2023-09-29},
	date = {2021-12},
	file = {Full Text PDF:C\:\\Users\\vogeler\\Zotero\\storage\\W5Q84UEG\\Blouin et al. - 2021 - Transferring Modern Named Entity Recognition to th.pdf:application/pdf},
}

@article{torres_aguilar_automatic_2022,
	title = {Automatic medieval charters structure detection : A Bi-{LSTM} linear segmentation approach},
	volume = {2022},
	issn = {2416-5999},
	url = {https://jdmdh.episciences.org/9825},
	doi = {10.46298/jdmdh.8646},
	shorttitle = {Automatic medieval charters structure detection},
	abstract = {This paper presents a model aiming to automatically detect sections in medieval Latin charters. These legal sources are some of the most important sources for medieval studies as they reflect economic and social dynamics as well as legal and institutional writing practices. An automatic linear segmentation can greatly facilitate charter indexation and speed up the recovering of evidence to support historical hypothesis by the means of granular inquiries on these raw, rarely structured sources. Our model is based on a Bi-{LSTM} approach using a final {CRF}-layer and was trained using a large, annotated collection of medieval charters (4,700 documents) coming from Lombard monasteries: the {CDLM} corpus (11th-12th centuries). The evaluation shows a high performance in most sections on the test-set and on an external evaluation corpus consisting of the Montecassino abbey charters (10th-12th centuries). We describe the architecture of the model, the main problems related to the treatment of medieval Latin and formulaic discourse, and we discuss some implications of the results in terms of record-keeping practices in High Middle Ages.},
	journaltitle = {Journal of Data Mining \& Digital Humanities},
	author = {Torres Aguilar, Sergio and Chastang, Pierre and Tannier, Xavier},
	urldate = {2023-09-30},
	date = {2022-10-30},
	langid = {english},
	note = {Publisher: Episciences.org},
	file = {Full Text PDF:C\:\\Users\\vogeler\\Zotero\\storage\\WGMGPGJD\\Aguilar et al. - 2022 - Automatic medieval charters structure detection  .pdf:application/pdf},
}

@article{ehrmann_named_2023,
	title = {Named Entity Recognition and Classification in Historical Documents: A Survey},
	volume = {56},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3604931},
	doi = {10.1145/3604931},
	shorttitle = {Named Entity Recognition and Classification in Historical Documents},
	abstract = {After decades of massive digitisation, an unprecedented number of historical documents are available in digital format, along with their machine-readable texts. While this represents a major step forward with respect to preservation and accessibility, it also opens up new opportunities in terms of content mining and the next fundamental challenge is to develop appropriate technologies to efficiently search, retrieve, and explore information from this ‘big data of the past’. Among semantic indexing opportunities, the recognition and classification of named entities are in great demand among humanities scholars. Yet, named entity recognition ({NER}) systems are heavily challenged with diverse, historical, and noisy inputs. In this survey, we present the array of challenges posed by historical documents to {NER}, inventory existing resources, describe the main approaches deployed so far, and identify key priorities for future developments.},
	pages = {27:1--27:47},
	number = {2},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Ehrmann, Maud and Hamdi, Ahmed and Pontes, Elvys Linhares and Romanello, Matteo and Doucet, Antoine},
	urldate = {2023-11-11},
	date = {2023-09-14},
	keywords = {digital humanities, natural language processing, historical documents, Named entity recognition and classification},
	file = {Full Text PDF:C\:\\Users\\vogeler\\Zotero\\storage\\3XIMC937\\Ehrmann et al. - 2023 - Named Entity Recognition and Classification in His.pdf:application/pdf},
}

@misc{ehrmann_named_2021,
	title = {Named Entity Recognition and Classification on Historical Documents: A Survey},
	url = {http://arxiv.org/abs/2109.11406},
	doi = {10.48550/arXiv.2109.11406},
	shorttitle = {Named Entity Recognition and Classification on Historical Documents},
	abstract = {After decades of massive digitisation, an unprecedented amount of historical documents is available in digital format, along with their machine-readable texts. While this represents a major step forward with respect to preservation and accessibility, it also opens up new opportunities in terms of content mining and the next fundamental challenge is to develop appropriate technologies to efficiently search, retrieve and explore information from this 'big data of the past'. Among semantic indexing opportunities, the recognition and classification of named entities are in great demand among humanities scholars. Yet, named entity recognition ({NER}) systems are heavily challenged with diverse, historical and noisy inputs. In this survey, we present the array of challenges posed by historical documents to {NER}, inventory existing resources, describe the main approaches deployed so far, and identify key priorities for future developments.},
	number = {{arXiv}:2109.11406},
	publisher = {{arXiv}},
	author = {Ehrmann, Maud and Hamdi, Ahmed and Pontes, Elvys Linhares and Romanello, Matteo and Doucet, Antoine},
	urldate = {2024-01-02},
	date = {2021-09-23},
	eprinttype = {arxiv},
	eprint = {2109.11406 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, A.1, I.2.7},
	file = {arXiv Fulltext PDF:C\:\\Users\\vogeler\\Zotero\\storage\\4P6DFLCC\\Ehrmann et al. - 2021 - Named Entity Recognition and Classification on His.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\vogeler\\Zotero\\storage\\U8LVEHVQ\\2109.html:text/html},
}

@inproceedings{tual_benchmark_2023,
	location = {Cham},
	title = {A Benchmark of Nested Named Entity Recognition Approaches in Historical Structured Documents},
	isbn = {978-3-031-41682-8},
	doi = {10.1007/978-3-031-41682-8_8},
	abstract = {Named Entity Recognition ({NER}) is a key step in the creation of structured data from digitised historical documents. Traditional {NER} approaches deal with flat named entities, whereas entities are often nested. For example, a postal address might contain a street name and a number. This work compares three nested {NER} approaches, including two state-of-the-art approaches using Transformer-based architectures. We introduce a new Transformer-based approach based on joint labelling and semantic weighting of errors, evaluated on a collection of 19th-century Paris trade directories. We evaluate approaches regarding the impact of supervised fine-tuning, unsupervised pre-training with noisy texts, and variation of {IOB} tagging formats. Our results show that while nested {NER} approaches enable extracting structured data directly, they do not benefit from the extra knowledge provided during training and reach a performance similar to the base approach on flat entities. Even though all 3 approaches perform well in terms of F1-scores, joint labelling is most suitable for hierarchically structured data. Finally, our experiments reveal the superiority of the {IO} tagging format on such data.},
	pages = {115--131},
	booktitle = {Document Analysis and Recognition - {ICDAR} 2023},
	publisher = {Springer Nature Switzerland},
	author = {Tual, Solenn and Abadie, Nathalie and Chazalon, Joseph and Duménieu, Bertrand and Carlinet, Edwin},
	editor = {Fink, Gernot A. and Jain, Rajiv and Kise, Koichi and Zanibbi, Richard},
	date = {2023},
	langid = {english},
	file = {Eingereichte Version:C\:\\Users\\vogeler\\Zotero\\storage\\E4X27HU4\\Tual et al. - 2023 - A Benchmark of Nested Named Entity Recognition App.pdf:application/pdf},
}
