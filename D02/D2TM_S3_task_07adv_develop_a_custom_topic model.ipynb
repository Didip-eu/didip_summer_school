{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tmS16HbXC9drW3iJd6S-5op2zBPPycMx","timestamp":1719770839048},{"file_id":"1XS7TBMjAFpVOEoAPWZjKIUQBr2QxSmSb","timestamp":1719768965453},{"file_id":"1n_DDWUnlT-Gu05kRH91_zoVRNhH98KQu","timestamp":1719768011369},{"file_id":"1qXt3LkaAM5oLuizaU52BFn9JAPBQkX3z","timestamp":1719764522902},{"file_id":"170KEhJVfxKE3MGKXjUD6QXtG4HAgGO-p","timestamp":1719763542190},{"file_id":"1kPvkVRcJr8SYVxWOfOp2yUuQehaYGLFX","timestamp":1719761347770}],"authorship_tag":"ABX9TyM+jbIiHTDWGI+HA1mejd1K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Advanced"],"metadata":{"id":"BQOIp-kQ7o33"}},{"cell_type":"markdown","source":["## Task 01: Develop a custom topic model tailored to the linguistic features of a specific medieval language.\n","\n","Description: This code applies topic modeling to Medieval Latin texts, incorporating linguistic knowledge to enhance the accuracy and interpretability of the results. The aim is to discover meaningful topics within the texts and assess the quality of the extracted topics.\n","\n","Hints:\n","\n","- Research relevant linguistic resources (e.g., dictionaries, grammars)\n","- Experiment with different model architectures (e.g., LDA with linguistic constraints).\n","\n","\n","**Libraries:**\n","\n","* **nltk:**\n","    * `tokenize`: Splits text into words (tokens).\n","* **gensim:**\n","    * `corpora`: Creates a dictionary and corpus for topic modeling.\n","    * `models`: Provides the base LDA model for customization.\n","* **string:**  Handles string manipulations (like removing punctuation).\n","* **numpy:** Performs numerical calculations.\n","* **matplotlib.pyplot:**  Visualizes results (not used in the current code, but could be for future analysis).\n","* **collections.defaultdict:** Provides convenient dictionary-like storage.\n","* **re:** Provides regular expression matching operations.\n","\n","**Code Structure:**\n","\n","1. **Preprocessing with Linguistic Knowledge:**\n","   * `preprocess_medieval_latin` function:\n","     * Tokenizes text.\n","     * Converts to lowercase.\n","     * Removes punctuation and numbers.\n","     * Normalizes Medieval Latin orthography (e.g., 'j' to 'i', 'v' to 'u').\n","     * Resolves common abbreviations (e.g., 'dns' to 'dominus').\n","     * Removes stop words.\n","\n","2. **Morphological Analysis (Optional):**\n","   * `get_stem` function (placeholder):\n","     * Intended for stemming words to their base forms. Requires implementation or integration with a Medieval Latin stemmer.\n","\n","3. **Custom Dictionary Creation:**\n","   * `MedievalLatinDictionary` class:\n","     * Inherits from `gensim.corpora.Dictionary`.\n","     * Creates a dictionary with additional stem information for each token.\n","\n","4. **Custom LDA Model:**\n","   * `MedievalLatinLDA` class:\n","     * Inherits from `gensim.models.LdaModel`.\n","     * Allows for incorporating linguistic knowledge during topic inference (this part is left as a placeholder for customization).\n","\n","5. **Main Process:**\n","   * Load sample Medieval Latin texts.\n","   * Preprocess texts using the custom function.\n","   * Create a custom dictionary.\n","   * Create a corpus using the dictionary.\n","   * Train the custom LDA model.\n","   * Print the top words for each topic.\n","   * Calculate and print the topic coherence score.\n","\n","**Key Points and Refinements:**\n","\n","* **Linguistic Adaptation:** The code is specifically designed for Medieval Latin, addressing unique orthographic and morphological features.\n","* **Customization Potential:** Provides a framework for incorporating more sophisticated linguistic rules and knowledge into the topic modeling process.\n","* **Topic Coherence:** Assesses the interpretability of the topics discovered by the model.\n","\n"],"metadata":{"id":"zRerVQ90tLgZ"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D56pTmCZ7WUF","executionInfo":{"status":"ok","timestamp":1719771111605,"user_tz":-120,"elapsed":2159,"user":{"displayName":"Tamas","userId":"07327650368274908773"}},"outputId":"6aad7b3d-148a-4b33-9402-3a61c00d1b94"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["Top words for each topic:\n","Topic: 0 \n","Words: 0.077*\"erat\" + 0.077*\"uerbum\" + 0.077*\"es\" + 0.077*\"noster\" + 0.077*\"caelis\" + 0.077*\"tuum\" + 0.077*\"pater\" + 0.077*\"nomen\" + 0.077*\"sanctificetur\" + 0.077*\"deum\"\n","\n","Topic: 1 \n","Words: 0.077*\"uerbum\" + 0.077*\"erat\" + 0.077*\"es\" + 0.077*\"noster\" + 0.077*\"pater\" + 0.077*\"caelis\" + 0.077*\"sanctificetur\" + 0.077*\"tuum\" + 0.077*\"nomen\" + 0.077*\"principio\"\n","\n","Topic: 2 \n","Words: 0.077*\"uerbum\" + 0.077*\"erat\" + 0.077*\"es\" + 0.077*\"noster\" + 0.077*\"caelis\" + 0.077*\"nomen\" + 0.077*\"pater\" + 0.077*\"sanctificetur\" + 0.077*\"principio\" + 0.077*\"tuum\"\n","\n","Topic: 3 \n","Words: 0.254*\"uerbum\" + 0.254*\"erat\" + 0.095*\"apud\" + 0.095*\"deus\" + 0.095*\"principio\" + 0.095*\"deum\" + 0.016*\"es\" + 0.016*\"tuum\" + 0.016*\"sanctificetur\" + 0.016*\"caelis\"\n","\n","Topic: 4 \n","Words: 0.125*\"nomen\" + 0.125*\"sanctificetur\" + 0.125*\"pater\" + 0.125*\"tuum\" + 0.125*\"caelis\" + 0.125*\"noster\" + 0.125*\"es\" + 0.021*\"erat\" + 0.021*\"uerbum\" + 0.021*\"principio\"\n","\n","Topic Coherence: 0.08105956953597629\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","\n","from nltk.tokenize import word_tokenize\n","import gensim\n","from gensim import corpora\n","import string\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","from gensim.models import LdaModel\n","from gensim.models.ldamodel import LdaState\n","\n","# 1. Preprocessing with linguistic knowledge\n","def preprocess_medieval_latin(text):\n","    # Tokenize\n","    tokens = word_tokenize(text.lower())\n","\n","    # Remove punctuation and numbers\n","    tokens = [token for token in tokens if token not in string.punctuation and not token.isdigit()]\n","\n","    # Apply Medieval Latin specific rules\n","    tokens = [normalize_medieval_latin(token) for token in tokens]\n","\n","    # Remove stopwords\n","    stopwords = set(['et', 'in', 'ad', 'ut', 'cum', 'non', 'qui', 'ab', 'ex', 'de'])\n","    tokens = [token for token in tokens if token not in stopwords]\n","\n","    return tokens\n","\n","def normalize_medieval_latin(token):\n","    # Apply Medieval Latin orthographic normalizations\n","    token = re.sub(r'[jJ]', 'i', token)\n","    token = \"SOMETHING SIMILAR IS MISSING\"\n","\n","    # Normalize common abbreviations\n","    abbreviations = {\n","        'dns': 'dominus',\n","        'xps': 'christus',\n","        \"ADD MORE ABREVIATION OR LEVERAGE ONLINE SOURCE\"\n","    }\n","    return abbreviations.get(token, token)\n","\n","# 2. Morphological analysis\n","def get_stem(word):\n","    # Implement or use a Medieval Latin stemmer\n","    # This is a placeholder function\n","    return word\n","\n","# 3. Custom dictionary creation\n","class MedievalLatinDictionary(corpora.Dictionary):\n","    def __init__(self, documents):\n","        self.stems = {}\n","        super().__init__(documents)\n","        self._create_stems()\n","\n","    def _create_stems(self):\n","        for token in self.token2id:\n","            self.stems[token] = get_stem(token)\n","\n","    def doc2bow(self, document, allow_update=False, return_missing=False):\n","        # Override to use stems\n","        stemmed_doc = [self.stems.get(token, token) for token in document]\n","        return super().doc2bow(stemmed_doc, allow_update, return_missing)\n","\n","# 4. Custom LDA model\n","class MedievalLatinLDA(LdaModel):\n","    def __init__(self, corpus=None, id2word=None, num_topics=100, **kwargs):\n","        super().__init__(corpus=corpus, id2word=id2word, num_topics=num_topics, **kwargs)\n","\n","    def get_document_topics(self, bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False):\n","        # Override to incorporate linguistic knowledge\n","        # This is where you could add constraints based on syntax or semantics\n","        return super().get_document_topics(bow, minimum_probability, minimum_phi_value, per_word_topics)\n","\n","# 5. Main process\n","# Sample Medieval Latin texts (replace with your corpus)\n","texts = [\n","    \"Pater noster, qui es in caelis, sanctificetur nomen tuum.\",\n","    \"In principio erat Verbum, et Verbum erat apud Deum, et Deus erat Verbum.\",\n","    # Add more texts\n","]\n","\n","# Preprocess texts\n","processed_texts = [preprocess_medieval_latin(text) for text in texts]\n","\n","# Create custom dictionary\n","dictionary = MedievalLatinDictionary(processed_texts)\n","\n","# Create corpus\n","corpus = [dictionary.doc2bow(text) for text in processed_texts]\n","\n","# Train custom LDA model\n","num_topics = 5  # Adjust as needed\n","lda_model = MedievalLatinLDA(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n","\n","# Print top words for each topic\n","print(\"Top words for each topic:\")\n","for idx, topic in lda_model.print_topics(-1):\n","    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n","\n","# Calculate topic coherence\n","coherence_model = gensim.models.CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n","coherence = coherence_model.get_coherence()\n","print(f\"Topic Coherence: {coherence}\")"]},{"cell_type":"markdown","source":["## Solution"],"metadata":{"id":"2e7ywGHTu2rr"}},{"cell_type":"markdown","source":["1. THE SOLUTIONS ARE FULLY FLEXIBLE"],"metadata":{"id":"lg3Kz4zwu53x"}}]}